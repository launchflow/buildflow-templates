project: launchflow-model-serving
pulumi_config:
    stacks:
    -   name: local
        backend_url: file://./.buildflow/_pulumi/local
    pulumi_home: ./.buildflow/_pulumi
entry_point: main:app
build_ignores:
- llama-2-7b-chat.ggmlv3.q2_K.bin
